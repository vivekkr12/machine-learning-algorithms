{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": "# Lasso regression\n\n*Linear regression with least square loss with $L_1$ regularization penalty*\n\n---\n* [Implementation in Python](../pymlalgo/regression/lasso_regression.py)\n* [Demo](../demo/lasso_regression_demo.ipynb)\n---\n\n### Symbols and Conventions\nRefer to [Symbols and Conventions](symbols_and_conventions.ipynb) for details. In summary:\n* $n$ is the number of training examples\n* $d$ is the number of features in each training example (a.k.a the dimension of the training example)\n* $X$ is the features matrix of shape $n \\times d$\n* $Y$ is the labels matrix of shape $n \\times 1$\n* $beta$ is the weight matrix of shape $d \\times 1$\n\n### Loss and Cost Function\nThe cost function for Lasso Regression can be written as**,\n\n \n\n$$F(\\beta) \u003d \\frac{1}{n} ||Y - X^{T}\\beta||_2^2 + \\lambda||\\beta||_1$$\n\n\nThe minimization problem is written as:\n\n$$min _{\\beta_j \\in {\\rm I\\!R} ^{1}} F(\\beta) \u003d \\frac{1}{n} ||Y - X^{T}\\beta||_2^2 + \\lambda||\\beta||_1$$\n\nwhere  $j \u003d 1, 2, 3, ..., d$\n\nWhile minimizing w.r.t $\\beta_j$ all the other betas, $\\beta_1, \\beta_2, ..., \\beta_{j-1}, \\beta_{j+1}, ...., \\beta_d$ are held constant.\n\n \n\n \n### Gradient Derivation\n\nLet\u0027s assume the first term of the objective function as $g(\\beta)$ and the second term as $h(\\beta)$\n\n \n\n \n\nSince $g$ is differentiable, the sub gradient will be equal to the gradient. We can find the derivative using the chain rule:\n\n \n\n$$\\partial_{\\beta_j} g(\\beta) \u003d \\triangledown _{\\beta_j} (\\beta) \u003d -\\frac{2}{n}X_j(Y-X^T\\beta)$$\n\n$$\u003d-\\frac{2}{n}X_j(Y-X_j^T\\beta_j - X_{-j}^{T}\\beta_{-j})$$\n\nwhere $X_{-j}$ and ${\\beta_{-j}}$ are the predictor matrix and the coefficients vector with the $j^{th}$ dimension removed. \n\n$$\u003d-\\frac{2}{n}X_j(Y - X_{-j}^{T}\\beta_{-j}) - \\frac{2}{n}X_j(-X_j^T\\beta_j)$$\n\n$$\u003d-\\frac{2}{n}X_j(Y - X_{-j}^{T}\\beta_{-j}) - \\frac{2}{n}(-1)X_jX_j^T\\beta_j)$$\n\n$$\u003d-\\frac{2}{n}X_j(Y - X_{-j}^{T}\\beta_{-j}) - \\frac{2}{n}(-1)||X_j||_2^2\\beta_j$$\n\n$$\u003d-\\frac{2}{n}(X_j(Y - X_{-j}^{T}\\beta_{-j}) - ||X_j||_2^2\\beta_j)$$\n\n \n\nLet\u0027s say that, $z_j \u003d ||X_j||_2^2$ and \n\n$R_{-j} \u003d Y - X_{-j}^{T}\\beta_{-j}$. \n\nThus we can write the equation as :\n\n$$\u003d-\\frac{2}{n}(X_jR_{-j} - \\beta_jz_j)$$\n\n \n\nNow, let\u0027s tackle $h(\\beta)$\n\n$$h(\\beta) \u003d \\lambda||\\beta||_1 \u003d \\sum_{j\u003d1}^{d}|\\beta_j|$$\n\ndifferentiating w.r.t $\\beta_j$, we will only get the derivative w.r.t $\\beta_j$ as all other terms will be 0.\n\n$$\\partial _{\\beta_j} h(\\beta) \u003d \\partial _{\\beta_j} (\\lambda|\\beta_j|) \u003d \\begin{cases}\\lambda \u0026 \\beta \u003e 0 \\\\\n-\\lambda \u0026 \\beta \u003c 0 \\\\\nv\\lambda  \u0026 \\beta \u003d 0, v \\in [-1, 1] \\\\\n\\end{cases}$$\n\nUsing the results and combining $g$ and $h$, we can write\n\n$$\\partial_{\\beta_j} F(\\beta) \u003d\\begin{cases}-\\frac{2}{n}(X_jR_{-j} - \\beta_jz_j) + \\lambda \u0026 \\beta \u003e 0 \\\\\n-\\frac{2}{n}(X_jR_{-j} - \\beta_jz_j)-\\lambda \u0026 \\beta \u003c 0 \\\\\n-\\frac{2}{n}(X_jR_{-j} - \\beta_jz_j) + v\\lambda  \u0026 \\beta \u003d 0, v \\in [-1, 1] \\\\\n\\end{cases}$$\n\nEquating all the three cases to 0, we get \n\n$$\\beta_j \u003d\\begin{cases}\\frac{\\lambda + \\frac{2}{n}x_j R_{-j}}{\\frac{2}{n}z_j} \u0026 \\frac{2}{n}x_iR_{-j} \\le -\\lambda \\\\\n\\frac{-\\lambda + \\frac{2}{n}x_j R_{-j}}{\\frac{2}{n}z_j} \u0026 \\frac{2}{n}x_iR_{-j} \\ge \\lambda \\\\\n0 \u0026 |\\frac{2}{n}x_iR_{-j}| \\ge \\lambda\\\\\n\\end{cases}$$"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}